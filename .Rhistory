El error estandar(SE) para la diferencia entre estas dos proporciones:
$$
SE = \sqrt{\frac{0.04831506*(1-0.04831506)}{2463}+\frac{0.1270808*(1-0.1270808)}{2463}} = 0.007981708
$$
Para un nivel de confianza del 95% valor de error es 0.05, y el z-value
$$
Z_{1-α/2}=qnorm(p=0.975,mean=0,sd=1)=1.96
$$
El intervalo es:
```{r}
1.96*0.007981708
0.1270808-0.01564415-0.04831506
0.1270808+0.01564415-0.04831506
```
$$
Intervalo:[0.063 \ - \ 0.094]
$$
Para este estadístico con un nivel de confianza del 95% se tiene un margen de error de 6.31 puntos.
LA solución con código R:
```{r}
prop.test(x = c(119 ,313), n = c(2463, 2463), conf.level = 0.95,alternative = "two.sided", correct = FALSE)
```
Nuestro p-valor es menor a 2.2e-16, que es menor a nuestro factor de significación $\alpha$ = 0.05, rechazamos la hipótesis nula $H_{0}\::\:P_{1}= P_{2}$ aceptando como cierta la hipotesis alternativa $H_{1}\::\: P_{1}<> P_{2}$. La probabilidad de haber cometido un error de tipo 1 sera nuestro nivel de significación, $\alpha$ = 0.05. Para un p-valor menor a 2.2e-16 la hipótesis nula tiene una probabilidad de menos del 0.1% de ser cierta.
---
title: "Práctica final E-SHOPS"
output:
pdf_document: default
word_document: default
html_notebook: default
---
Procedemos a cargar los datos proporcionados sobre la práctica de E-SHOPS.
```{r message=FALSE}
library(dplyr)
library(tidyr)
library(readr)
eshop <- read.csv("/Users/eva/Downloads/eshop.csv",header=TRUE, sep=";")
```
## 1.- **ESTUDIO DESCRIPTIVO**
Primero analizamos los datos y vemos el número de correspondencias para cada característica.
Luego creamos una serie de comparativas entre compras desde casa o desde el trabajo en los barplots.
```{r analisis descriptivo datos}
summary(eshop)
barplot(prop.table(table(eshop$eshop.home)),col=c('orange','blue','green'),ylim=c(0,1), main="E-SHOP HOME",ylab="Frecuencias Relativas")
text(0.7, 0.06, prop.table(table(eshop$eshop.home))[1])
text(1.9, 0.93, prop.table(table(eshop$eshop.home))[2])
text(3.1, 0.18, prop.table(table(eshop$eshop.home))[3])
barplot(prop.table(table(eshop$eshop.work)),col=c('green','orange','blue'),ylim=c(0,1.1), main="E-SHOP WORK",ylab="Frecuencias Relativas")
text(0.7, 0.1, prop.table(table(eshop$eshop.work))[1])
text(1.9, 0.06, prop.table(table(eshop$eshop.work))[2])
text(3.1, 1, prop.table(table(eshop$eshop.work))[3])
```
Como podemos ver en los barplots, el 87% de las personas no hacen compras en casa y el 95% no las hacen desde el trabajo.
Por el contrario, el 12% realizan compras online desde casa y el 4% desde el trabajo.
<!-- table(eshop$sex, eshop$eshop.work)  -->
<!-- table(eshop$sex, eshop$eshop.home)  -->
<!-- prop.table(table(eshop$sex)) #en porcentaje -->
<!-- barplot(table(eshop$sex)) -->
<!-- barplot(table(eshop$eshop.work)) -->
<!-- barplot(table(eshop$eshop.home)) -->
## 2.- **BAYES Y FRECUENTISTA**
Para verificar si el porcentaje teórico de compras en casa es similar al de compras en el trabajo, la herramienta **Bayesiana** que usaremos serán los intervalos de credibilidad.
$$
eshop_{home} =
\left\{
\begin{array}{l}
NO =2149   \  (87.25132 \%)  \\
SI =313  \  (12.70808 \%)  \\
NC = 1 \ (0.04060089 \%) \\
\end{array}
\right .
$$
$$
TOTAL \  DE \  PARTICIPANTES = 2463
$$
$$
eshop_{work} =
\left\{
\begin{array}{l}
NO = 2342   \  (95.08729 \%)  \\
SI = 119   \  (4.831506 \%)  \\
NC = 2   \  (0.08120179 \%) \\
\end{array}
\right .
$$
$$
TOTAL \  DE \  PARTICIPANTES = 2463
$$
```{r bayes}
```
Para verificar si el porcentaje teórico de compras en casa es similar al de compras en el trabajo, la herramienta **Frecuentista** que usaremos el Teorema Central del Límite.
Se puede acercar la distribución a una normal dado el teorema central del límite.
Teóricamente:
(pHome−pWork)=0.1270808 - 0.04831506 = 0.07876574
Ahora calculo SE para la diferencia de proporciones:
$$
SE = \sqrt{\frac{0.04831506*(1-0.04831506)}{2463}+\frac{0.1270808*(1-0.1270808)}{2463}} = 0.007981708
$$
Calculo de Z para una confianza del 95% cuyo valor de error es del 0.05%:
$$
Z_{1-α/2}=qnorm(p=0.975,mean=0,sd=1)=1.96
$$
El intervalo es:
```{r}
1.96*0.007981708
0.1270808-0.01564415-0.04831506
0.1270808+0.01564415-0.04831506
```
$$
Intervalo:[0.063 \ - \ 0.094]
$$
Se puede afirmar del 95% que existe entre un 6.3% y un 9.4% más de realización de compras desde casa que desde el trabajo.
```{r frecuentista}
prop.test(x = c(313, 119), n = c(2463, 2463), conf.level = 0.95,alternative = "two.sided", correct = FALSE)
```
## 3.- **CONTRASTE DE HIPÓTESIS**
Nuestra hipótesis consiste en comprobar si la propoción de encuestados que hacen compras on-line desde el trabajo ($P_{1}$) es igual a la proporción de encuestados que hacen compras on-line desde el hogar ($p_{2}$).
($H_{0}$) en este caso, sería:
$$
H_{0} \ : P_{1} = P_{2}
$$
Y ($H_{1}$) sería:
$$
H_{1} \ : \ P_{1}<> P_{2} , es\: decir,\:  (H_{1}\ : \ P_{1}< P_{2} \ ; \:H_{1}\ : \ P_{1}> P_{2})
$$
Se puede hacer de esa forma o calculando un intervalo de confianza para la diferencia de ambos porcentajes, es decir,
$$
P_{1} - P_{2}
$$
Teniendo en cuenta las proporciones de ($P_{1}$) = 0.04831506 que son las compras desde el trabajo y ($p_{2}$) = 0.1270808 que son las compras desde el trabajo, teóricamente $P_{1}- P_{2} = -0.07876573$
```{r}
prop.table(table(eshop$eshop.work))[1]
prop.table(table(eshop$eshop.home))[3]
prop.table(table(eshop$eshop.work))[1]- prop.table(table(eshop$eshop.home))[3]
```
El error es el que hemos calculado anteriormente, en el apartado frecuentista:
El error estandar(SE) para la diferencia entre estas dos proporciones:
$$
SE = \sqrt{\frac{0.04831506*(1-0.04831506)}{2463}+\frac{0.1270808*(1-0.1270808)}{2463}} = 0.007981708
$$
Para un nivel de confianza del 95% valor de error es 0.05, y el z-value
$$
Z_{1-α/2}=qnorm(p=0.975,mean=0,sd=1)=1.96
$$
El intervalo es:
```{r}
1.96*0.007981708
0.1270808-0.01564415-0.04831506
0.1270808+0.01564415-0.04831506
```
$$
Intervalo:[0.063 \ - \ 0.094]
$$
Para este estadístico con un nivel de confianza del 95% se tiene un margen de error de 6.31 puntos.
LA solución con código R:
```{r}
prop.test(x = c(119 ,313), n = c(2463, 2463), conf.level = 0.95,alternative = "two.sided", correct = FALSE)
```
Nuestro p-valor es menor a 2.2e-16, que es menor a nuestro factor de significación $\alpha$ = 0.05, rechazamos la hipótesis nula $H_{0}\::\:P_{1}= P_{2}$ aceptando como cierta la hipotesis alternativa $H_{1}\::\: P_{1}<> P_{2}$. La probabilidad de haber cometido un error de tipo 1 sera nuestro nivel de significación, $\alpha$ = 0.05. Para un p-valor menor a 2.2e-16 la hipótesis nula tiene una probabilidad de menos del 0.1% de ser cierta.
---
title: "Práctica final E-SHOPS"
output:
pdf_document: default
word_document: default
html_notebook: default
---
Procedemos a cargar los datos proporcionados sobre la práctica de E-SHOPS.
```{r message=FALSE}
library(dplyr)
library(tidyr)
library(readr)
eshop <- read.csv("/Users/eva/Downloads/eshop.csv",header=TRUE, sep=";")
```
## 1.- **ESTUDIO DESCRIPTIVO**
Primero analizamos los datos y vemos el número de correspondencias para cada característica.
Luego creamos una serie de comparativas entre compras desde casa o desde el trabajo en los barplots.
```{r analisis descriptivo datos}
summary(eshop)
barplot(prop.table(table(eshop$eshop.home)),col=c('orange','blue','green'),ylim=c(0,1), main="E-SHOP HOME",ylab="Frecuencias Relativas")
text(0.7, 0.06, prop.table(table(eshop$eshop.home))[1])
text(1.9, 0.93, prop.table(table(eshop$eshop.home))[2])
text(3.1, 0.18, prop.table(table(eshop$eshop.home))[3])
barplot(prop.table(table(eshop$eshop.work)),col=c('green','orange','blue'),ylim=c(0,1.1), main="E-SHOP WORK",ylab="Frecuencias Relativas")
text(0.7, 0.1, prop.table(table(eshop$eshop.work))[1])
text(1.9, 0.06, prop.table(table(eshop$eshop.work))[2])
text(3.1, 1, prop.table(table(eshop$eshop.work))[3])
```
Como podemos ver en los barplots, el 87% de las personas no hacen compras en casa y el 95% no las hacen desde el trabajo.
Por el contrario, el 12% realizan compras online desde casa y el 4% desde el trabajo.
<!-- table(eshop$sex, eshop$eshop.work)  -->
<!-- table(eshop$sex, eshop$eshop.home)  -->
<!-- prop.table(table(eshop$sex)) #en porcentaje -->
<!-- barplot(table(eshop$sex)) -->
<!-- barplot(table(eshop$eshop.work)) -->
<!-- barplot(table(eshop$eshop.home)) -->
## 2.- **BAYES Y FRECUENTISTA**
Para verificar si el porcentaje teórico de compras en casa es similar al de compras en el trabajo, la herramienta **Bayesiana** que usaremos serán los intervalos de credibilidad.
$$
eshop_{home} =
\left\{
\begin{array}{l}
NO =2149   \  (87.25132 \%)  \\
SI =313  \  (12.70808 \%)  \\
NC = 1 \ (0.04060089 \%) \\
\end{array}
\right .
$$
$$
TOTAL \  DE \  PARTICIPANTES = 2463
$$
$$
eshop_{work} =
\left\{
\begin{array}{l}
NO = 2342   \  (95.08729 \%)  \\
SI = 119   \  (4.831506 \%)  \\
NC = 2   \  (0.08120179 \%) \\
\end{array}
\right .
$$
$$
TOTAL \  DE \  PARTICIPANTES = 2463
$$
```{r bayes}
```
Para verificar si el porcentaje teórico de compras en casa es similar al de compras en el trabajo, la herramienta **Frecuentista** que usaremos el Teorema Central del Límite.
Se puede acercar la distribución a una normal dado el teorema central del límite.
Teóricamente:
(pHome−pWork)=0.1270808 - 0.04831506 = 0.07876574
Ahora calculo SE para la diferencia de proporciones:
$$
SE = \sqrt{\frac{0.04831506*(1-0.04831506)}{2463}+\frac{0.1270808*(1-0.1270808)}{2463}} = 0.007981708
$$
Calculo de Z para una confianza del 95% cuyo valor de error es del 0.05%:
$$
Z_{1-α/2}=qnorm(p=0.975,mean=0,sd=1)=1.96
$$
El intervalo es:
```{r}
1.96*0.007981708
0.1270808-0.01564415-0.04831506
0.1270808+0.01564415-0.04831506
```
$$
Intervalo:[0.063 \ - \ 0.094]
$$
Se puede afirmar del 95% que existe entre un 6.3% y un 9.4% más de realización de compras desde casa que desde el trabajo.
```{r frecuentista}
prop.test(x = c(313, 119), n = c(2463, 2463), conf.level = 0.95,alternative = "two.sided", correct = FALSE)
```
## 3.- **CONTRASTE DE HIPÓTESIS**
Nuestra hipótesis consiste en comprobar si la propoción de encuestados que hacen compras on-line desde el trabajo ($P_{1}$) es igual a la proporción de encuestados que hacen compras on-line desde el hogar ($p_{2}$).
($H_{0}$) en este caso, sería:
$$
H_{0} \ : P_{1} = P_{2}
$$
Y ($H_{1}$) sería:
$$
H_{1} \ : \ P_{1}<> P_{2} , es\: decir,\:  (H_{1}\ : \ P_{1}< P_{2} \ ; \:H_{1}\ : \ P_{1}> P_{2})
$$
Se puede hacer de esa forma o calculando un intervalo de confianza para la diferencia de ambos porcentajes, es decir,
$$
P_{1} - P_{2}
$$
Teniendo en cuenta las proporciones de ($P_{1}$) = 0.04831506 que son las compras desde el trabajo y ($p_{2}$) = 0.1270808 que son las compras desde el trabajo, teóricamente $P_{1}- P_{2} = -0.07876573$
```{r}
prop.table(table(eshop$eshop.work))[1]
prop.table(table(eshop$eshop.home))[3]
prop.table(table(eshop$eshop.work))[1]- prop.table(table(eshop$eshop.home))[3]
```
El error es el que hemos calculado anteriormente, en el apartado frecuentista:
El error estandar(SE) para la diferencia entre estas dos proporciones:
$$
SE = \sqrt{\frac{0.04831506*(1-0.04831506)}{2463}+\frac{0.1270808*(1-0.1270808)}{2463}} = 0.007981708
$$
Para un nivel de confianza del 95% valor de error es 0.05, y el z-value
$$
Z_{1-α/2}=qnorm(p=0.975,mean=0,sd=1)=1.96
$$
El intervalo es:
```{r}
1.96*0.007981708
0.1270808-0.01564415-0.04831506
0.1270808+0.01564415-0.04831506
```
$$
Intervalo:[0.063 \ - \ 0.094]
$$
Para este estadístico con un nivel de confianza del 95% se tiene un margen de error de 6.31 puntos.
LA solución con código R:
```{r}
prop.test(x = c(119 ,313), n = c(2463, 2463), conf.level = 0.95,alternative = "two.sided", correct = FALSE)
```
Nuestro p valor es menor a 2.2e-16, que es menor a nuestro factor de significación $\alpha$ = 0.05, rechazamos la hipótesis nula $H_{0}\::\:P_{1}= P_{2}$ aceptando como cierta la hipotesis alternativa $H_{1}\::\: P_{1}<> P_{2}$. La probabilidad de haber cometido un error de tipo 1 sera nuestro nivel de significación, $\alpha$ = 0.05. Para un p-valor menor a 2.2e-16 la hipótesis nula tiene una probabilidad de menos del 0.1% de ser cierta.
```{r message=FALSE}
library(dplyr)
library(tidyr)
library(readr)
eshop <- read.csv("/Users/eva/Downloads/eshop.csv",header=TRUE, sep=";")
summary(eshop)
barplot(prop.table(table(eshop$eshop.home)),col=c('orange','blue','green'),ylim=c(0,1), main="E-SHOP HOME",ylab="Frecuencias Relativas")
text(0.7, 0.06, prop.table(table(eshop$eshop.home))[1])
text(1.9, 0.93, prop.table(table(eshop$eshop.home))[2])
text(3.1, 0.18, prop.table(table(eshop$eshop.home))[3])
barplot(prop.table(table(eshop$eshop.work)),col=c('green','orange','blue'),ylim=c(0,1.1), main="E-SHOP WORK",ylab="Frecuencias Relativas")
text(0.7, 0.1, prop.table(table(eshop$eshop.work))[1])
text(1.9, 0.06, prop.table(table(eshop$eshop.work))[2])
text(3.1, 1, prop.table(table(eshop$eshop.work))[3])
1.96*0.007981708
0.1270808-0.01564415-0.04831506
0.1270808+0.01564415-0.04831506
prop.test(x = c(313, 119), n = c(2463, 2463), conf.level = 0.95,alternative = "two.sided", correct = FALSE)
prop.table(table(eshop$eshop.work))[1]
prop.table(table(eshop$eshop.home))[3]
prop.table(table(eshop$eshop.work))[1]- prop.table(table(eshop$eshop.home))[3]
1.96*0.007981708
0.1270808-0.01564415-0.04831506
0.1270808+0.01564415-0.04831506
prop.test(x = c(119 ,313), n = c(2463, 2463), conf.level = 0.95,alternative = "two.sided", correct = FALSE)
library(knitr)
rmarkdown::render("/Users/eva/Desktop/PracticaFinalInferencia2.Rmd")
library(dplyr)
library(tidyr)
library(readr)
eshop <- read.csv("/Users/eva/Downloads/eshop.csv",header=TRUE, sep=";")
summary(eshop)
barplot(prop.table(table(eshop$eshop.home)),col=c('orange','blue','green'),ylim=c(0,1), main="E-SHOP HOME",ylab="Frecuencias Relativas")
text(0.7, 0.06, prop.table(table(eshop$eshop.home))[1])
text(1.9, 0.93, prop.table(table(eshop$eshop.home))[2])
text(3.1, 0.18, prop.table(table(eshop$eshop.home))[3])
barplot(prop.table(table(eshop$eshop.work)),col=c('green','orange','blue'),ylim=c(0,1.1), main="E-SHOP WORK",ylab="Frecuencias Relativas")
text(0.7, 0.1, prop.table(table(eshop$eshop.work))[1])
text(1.9, 0.06, prop.table(table(eshop$eshop.work))[2])
text(3.1, 1, prop.table(table(eshop$eshop.work))[3])
1.96*0.007981708
0.1270808-0.01564415-0.04831506
0.1270808+0.01564415-0.04831506
prop.test(x = c(313, 119), n = c(2463, 2463), conf.level = 0.95,alternative = "two.sided", correct = FALSE)
prop.table(table(eshop$eshop.work))[1]
prop.table(table(eshop$eshop.home))[3]
prop.table(table(eshop$eshop.work))[1]- prop.table(table(eshop$eshop.home))[3]
1.96*0.007981708
0.1270808-0.01564415-0.04831506
0.1270808+0.01564415-0.04831506
prop.test(x = c(119 ,313), n = c(2463, 2463), conf.level = 0.95,alternative = "two.sided", correct = FALSE)
install.packages("Hmisc")
library(dplyr)
library(tidyr)
library(readr)
library(ggplot2)
library(corrplot)
library(psych)
library(Hmisc)
ACMEC <- read_csv("/Users/eva/Desktop/ACME.csv", header=TRUE, sep=",")
ACMEC <- read_csv("/Users/eva/Desktop/ACME.csv",sep=",")
ACMEC <- read_csv("/Users/eva/Desktop/ACME.csv")
ACMEC <- read_csv("/Users/eva/Desktop/ACMEC.csv")
ACMEC <- read_csv("/Users/eva/Desktop/ACMETelephoneABT.csv")
ACMEC <- read_csv("/Users/eva/Desktop/ACMETelephoneABT.csv", header=TRUE, sep=",")
Hmisc::describe(ACMETelephoneABT.csv)
Hmisc::describe(ACMEC)
ACMEC <- read_csv("/Users/eva/Desktop/ACMETelephoneABT.csv")
show(ACEMC)
View(ACEMC)
View.table(ACEMC)
View(ACEMC)
ACMEC <- read_csv("/Users/eva/Desktop/ACMETelephoneABT.csv")
View(ACEMC)
View(ACMEC)
library(MASS)
help(Boston)
library(MASS)
dim(Boston)
n_data=dim(Boston)[1]
n_data
n_data=dim(Boston)[1]
#cogemos el 70% y de test el 30%
n_train=round(0.7*n_data)
n_test=n_data-n_train
indices=1:n_data
indices
indices_train= sample(indices,n_train)
indices_test=indices[-indices_train]
Boston_train=Boston[indices_train,]
Boston_test=Boston[indices_test,]
dim(Boston_train)
dim(Boston_test)
colnames(Boston)
lm.fit=lm(medv~lstat,data=Boston_train)
lm.fit
summary(lm.fit)
Yhat=predict(lm.fit,data.frame(lstat=Boston_train[,"lstat"]))
plot(Boston_train[,"lstat"],Boston_train[,"medv"])
plot(Boston_train[,"lstat"],Boston_train[,"medv"])
plot(Boston_train[,"lstat"],Boston_train[,"medv"])
abline(lm.fit)
abline(lm.fit)
plot(Boston_train[,"lstat"],Boston_train[,"medv"])
#abline le das el vector y te pinta la linea
abline(lm.fit)
plot(Boston_test[,"lstat"],Boston_test[,"medv"])
plot(Boston_test[,"lstat"],Boston_test[,"medv"])
abline(lm.fit)
plot(Boston_test[,"lstat"],Boston_test[,"medv"])
abline(lm.fit)
Yhat=predict(lm.fit,data.frame(lstat=Boston_train[,"lstat"]))
Yhat
Yreal=Boston_train[,"medv"]
Yreal
error_train=sum(abs(Yhat-Yreal))/length(Yreal)
error_train
Yhat=predict(lm.fit,data.frame(lstat=Boston_test[,"lstat"]))
Ytest
Yhat=predict(lm.fit,data.frame(lstat=Boston_test[,"lstat"]))
Yreal=Boston_test[,"medv"]
Yhat
Yreal
error_test=sum(abs(Yhat-Yreal))/length(Yreal)
error_test
n_data=dim(Boston)[1]
n_train=round(0.7*n_data)
n_test=n_data-n_train
indices=1:n_data
rep=100
error_train_rep=c()
error_test_rep=c()
for (i in 1:rep)
{
indices_train= sample(indices,n_train)
indices_test=indices[-indices_train]
Boston_train=Boston[indices_train,]
Boston_test=Boston[indices_test,]
lm.fit=lm(medv~.,data=Boston_train)
Yhat_train=predict(lm.fit,data.frame(Boston_train[,-14]))
Yreal_train=Boston_train[,"medv"]
error_train=sum(abs(Yhat_train-Yreal_train))/length(Yreal_train)
error_train_rep=c(error_train_rep,error_train)
Yhat_test=predict(lm.fit,data.frame(Boston_test[,-14]))
Yreal_test=Boston_test[,"medv"]
error_test=sum(abs(Yhat_test-Yreal_test))/length(Yreal_test)
error_test_rep=c(error_test_rep,error_test)
}
lm.fit
plot(Boston_test[,"lstat"],Boston_test[,"medv"])
abline(lm.fit)
summary(lm.fit)
plot(Yhat, Yreal_train)
plot(Yhat_train, Yreal_train)
error_test
error_test_rep
error_train_rep
mean(error_train_rep)
sd(error_train_rep)
mean(error_test_rep)
sd(error_test_rep)
install.packages("sparklyr")
shiny::runGadget(sparklyr::connection_spark_shinyapp(), viewer = .rs.embeddedViewer)
library(sparklyr)
library(dplyr)
spark_install(version = "2.3.2", hadoop_version = "2.7")
sc <- spark_connect(master = "local")
shiny::runGadget(sparklyr::connection_spark_shinyapp(), viewer = .rs.embeddedViewer)
library(sparklyr)
library(dplyr)
sc <- spark_connect(master = "local", version = "2.4.0")
shiny::runGadget(sparklyr::connection_spark_shinyapp(), viewer = .rs.embeddedViewer)
library(sparklyr)
library(dplyr)
sc <- spark_connect(master = "local")
library(readr)
library(caret)
install.packages("caret")
install.packages("caret")
install.packages("caret")
library(readr)
library(caret)
install.packages("caret")
library(caret)
install.packages("caret")
library(caret)
install.packages("rlang")
library(readr)
library(caret)
install.packages("rlang")
library(readr)
library(caret)
library(dplyr)
kc_house_data <- read_csv("data/kc_house_data.csv")
inTraining <- createDataPartition(pull(kc_house_data, price),p = .7, list = FALSE, times = 1)
house_training <- slice(kc_house_data, inTraining)
house_testing <- slice(kc_house_data, -inTraining)
View(house_training)
ids_duplicados <- house_training[which(duplicated(house_training$id)),]
View(ids_duplicados)
Hmisc::describe(house_training)
gglop(data = house_training) + geom_density(aes(sqft_above))
ggplop(data = house_training) + geom_density(aes(sqft_above))
library(ggplot2)
ggplop(data = house_training) + geom_density(aes(sqft_above))
ids_duplicados <- house_training[which(duplicated(house_training$id)),].sort()
ggplot(data = house_training) + geom_density(aes(sqft_above))
ggplot(data = house_training) + geom_density(aes(yr_built))
ggplot(data = house_training) + geom_density(aes(date))
max(house_training$yr_built)
hist(house_training$date,freq=FALSE,col="lightcyan")
hist(house_training$date,col="lightcyan")
hist(house_training$date)
library(readr)
library(caret)
library(dplyr)
library(ggplot2)
hist(house_training$date)
hist(house_training$date, breaks = "Sturges")
