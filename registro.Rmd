---
title: "Practica de Inteligencia y Analítica de Negocio"
author: "Eva Gordo Calleja, Javier Pérez Clemente"
date: "26 de Abril de 2019"
output:
  rmdformats::readthedown:
  self_contained: true
  thumbnails: true
  lightbox: true
  gallery: false
---

# Introducción

La base de datos a analizar contiene datos sobre los precios de venta sobre 2014 y 2015 en el condado de King, Estados Unidos. 

El objetivo de la práctica es construir un modelo de predicción para el precio de la vivienda (variable price), en función de tantas variables de entrada como estimemos conveniente.

# Limpieza de variables

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(readr)
library(dplyr)
library(Hmisc)
library(gtable)
library(grid)
library(gridExtra)
library(ggplot2)
library(VIM)
library(summarytools)
library(glmnet)
library(Matrix)

set.seed(12345)

source('transformations.R')
```

### Train y Test

Separación de los datos en training set (70% de los datos) y testing set (30% restante de los datos).
Primero leemos el archivo y se crea una partición para separar los datos en train y test.

```{r train test}
kc_house_data <- read_csv("data/kc_house_data.csv")
inTraining <- createDataPartition(pull(kc_house_data), p = .7, list = FALSE,times = 1)

house_training <- slice(kc_house_data, inTraining)
house_testing <- slice(kc_house_data, -inTraining)
```

### Exploratory Data Analysis (EDA)

El EDA se realiza sobre los datos de entrenamiento. Se identifican las posibles operaciones que debemos realizar sobre los datos.

De una forma general, se empieza a analizar los datos (tipo de variable, frecuencia, distribución, datos faltantes, etc.)
```{r}
summary(house_training)
```

### Eliminación de ids duplicados

Al hacer la limpieza con los datos de entrenamiento, encontramos duplicados en la variable `ID`. Se han ordenado en base a la variable `date` de manera descendente para quedarnos con las fechas más actuales y eliminar las casas duplicadas que han sufrido algún cambio como puede ser una nueva reforma o un nuevo valor del precio de la vivienda.

```{r}
duplicated_ids <- house_training[which(duplicated(house_training$id)),]
house_training_order <- house_training[order(house_training$date, decreasing = TRUE),]
house_training <- house_training_order[!duplicated(house_training_order$id), ]
```


### Variables binarias

En el caso de la variable `sqft_basement`, encontramos que el factor verdaderamente importante es si la casa tiene sótano o no, por lo que se ha decidido transformar esta variable a 0 si no tiene y 1 en el caso contrario.

Con la variable `yr_renovated` pasa lo mismo, contenía bastantes ceros, por lo que se han decidido cambiar esta dos variable por 0 si no ha sido renovado y 1 si lo ha sido.

```{r}
# Binary variables
house_training <- house_training %>% mutate(has_basement = if_else(sqft_basement == 0, 0,1))
house_training <- house_training %>% mutate(renovated = if_else(yr_renovated == 0, 0,1))

p1 <- house_training %>% ggplot() + geom_density(aes(sqft_basement), fill='tomato1')
p2 <- house_training %>% ggplot() + geom_bar(aes(has_basement), fill = 'aquamarine3')
p3 <- house_training %>% ggplot() + geom_density(aes(yr_renovated), fill='tomato1')
p4 <- house_training %>% ggplot() + geom_bar(aes(renovated), fill = 'aquamarine3')
grid.arrange(p1, p2, p3, p4, nrow=2)
```

### Imputación de variables

La variable bathrooms contiene valores a 0 y se reemplazará por NA porque consideramos que no puede existir una casa que tenga 0 baños. Por otro lado, La variable bedrooms contiene un único valor extremadamente átipico de 33 que parece ser un error.

```{r, echo=FALSE}
freq(house_training$bedrooms)
```

Primero se les imputa como NA y después se usa la función KNN con los 5 vecinos más cercanos en funcion de la superficie habitable, el número de pisos y si tiene sótano o no para asignarles un valor a los NAs.

```{r}
# Impute values
house_training$bedrooms <- house_training$bedrooms %>% dplyr::na_if(33)
house_training$bathrooms <- house_training$bathrooms %>% dplyr::na_if(0)
house_training <- kNN(house_training, variable = c("bedrooms"), dist_var = c("sqft_living", "floors", "has_basement"), k = 5, imp_var = FALSE)
house_training <- kNN(house_training, variable = c("bathrooms"), dist_var = c("sqft_living", "floors", "has_basement"), k = 5, imp_var = FALSE)

```


### Transformaciones logarítmicas

Las siguientes variables muestran distribuciones con grandes colas que indican que seria requerible transformarlas usando el logaritmo:

```{r, echo=FALSE, fig.height=7, fig.width=8}
# logarithmic transformations
house_training <- mutate(house_training, log_price = log(price))
house_training <- mutate(house_training, log_sqft_living = log(sqft_living))
house_training <- mutate(house_training, log_sqft_lot = log(sqft_lot))
house_training <- mutate(house_training, log_sqft_lot15 = log(sqft_lot15))

par(mfrow=c(2,4))
p1 <- house_training %>% ggplot() + geom_density(aes(price), fill='tomato1')
p2 <- house_training %>% ggplot() + geom_density(aes(log_price), fill = 'aquamarine3')
p3 <- house_training %>% ggplot() + geom_density(aes(sqft_living), fill='tomato1')
p4 <- house_training %>% ggplot() + geom_density(aes(log_sqft_living), fill = 'aquamarine3')
p5 <- house_training %>% ggplot() + geom_density(aes(sqft_lot), fill='tomato1')
p6 <- house_training %>% ggplot() + geom_density(aes(log_sqft_lot), fill = 'aquamarine3')
p7 <- house_training %>% ggplot() + geom_density(aes(sqft_lot15), fill='tomato1')
p8 <- house_training %>% ggplot() + geom_density(aes(log_sqft_lot15), fill = 'aquamarine3')

grid.arrange(p1, p2, p3, p4, p5, p6, p7, p8, nrow=4)
```

### Variables dummies

Transformamos la variable `grade` en un rango `grade_range` con dos únicos valores.

```{r}
house_training$grade_range <- ifelse(house_training$grade %in% c(1,2,3,4,5,6), 1, 
                              ifelse(house_training$grade %in% c(7,8,9),2,3)) 

p1 <- house_training %>% ggplot() + geom_bar(aes(grade), fill = 'tomato')
p2 <- house_training %>% ggplot() + geom_bar(aes(grade_range), fill = 'aquamarine3')

grid.arrange(p1, p2, nrow=1)
```

Creamos una variable dummy por cada uno de los valores de la nueva variable `grade_range`.
```{r}
grade <- factor(house_training$grade_range)
house_training <- house_training %>% cbind(model.matrix(~grade)[,-1])
```


### Eliminación de variables obsoletas

Finalmente, eliminamos todas las variables que han sido sustituidas por sus trnsformadas.

```{r}
house_training <- house_training %>% select(-c(id, sqft_basement, yr_renovated, grade, grade_range, price, sqft_living, sqft_lot, sqft_lot15))
```


# Selección de variables, entrenamiento y regularización del modelo

Para identificar qué variables son importantes y por tanto deben ser incluidas en el modelo, utilizamos el método LASSO (least absolute shrinkage and selection operator). Este método realiza selección de variables y estimación de parámetros simultanea, ya que reduce a cero los coeficientes de las variables que deben quedar fuera del modelo. 

Realizamos validación cruzada troceando el conjunto de entrenamiento en 10 rodajas, de forma que se relizan 10 iteraciones en las que una de las "rodajas" es utilizada como datos de validación y las demás como conjunto de entrenamiento. Así, podremos seleccionar el valor de lambda que minimice el error cuadrático medio y nos devuelva el modelo más regular.

```{r echo=TRUE}
#house_training <- na.omit(house_training)
x_train <- model.matrix(log_price~.,house_training)[,-1]
y_train <- house_training$log_price

cv.out <- cv.glmnet(x_train, y_train, alpha=1, nfolds=10, type.measure="mse")
plot(cv.out)
```

Se observa que el error cuadrático medio para lambda0 y lambda1 es muy pequeño, lo que es un buen síntoma. Nos quedamos con lambda.1se, 
que es el valor que proporciona el modelo mas regular cuyo error se encuentra a una unidad de errror estandar del mínimo.

```{r echo=TRUE}
cv.out$lambda.1se
```

De esta forma, obtenemos los coeficientes de la regresión para cada una de nuestras variables.

```{r echo=TRUE}
tmp_coeffs <- coef(cv.out, s = "lambda.1se")
tmp_coeffs
```

En este caso, el método LASSO nos indica que solo la variable transformada log_sqft_lot queda fuera del modelo.


# Evaluacion de los resultados.

Para comprobar como de bueno es nuestro modelo, utilizamos los datos de test, sobre los que es necesario aplicar las mismas transformaciones que hicimos sobre el conjunto de entrenamiento. Calculamos el error cuadrático medio para evaluar los resultados predichos.

```{r echo=TRUE, warning=FALSE}
house_testing <- transform(house_testing)
x_test <- data.matrix(house_testing %>% select(-log_price))
y_real_test = house_testing$log_price
y_predicted_test=predict(cv.out,newx = x_test, type = "response")


mean((y_real_test - y_predicted_test)^2)
```

Se trata realmente de un error pequeño (dos ordenes de magnitud por debajo de los datos predichos), lo que indica que nuestro modelo funciona razonablemente bien.