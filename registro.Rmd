---
title: "registro"
author: "Eva Gordo Calleja, Javier Pérez Clemente"
date: "March 1, 2019"
output:
  rmdformats::readthedown:
  self_contained: true
  thumbnails: true
  lightbox: true
  gallery: false
---

# House Sales in King County, USA

La base de datos a analizar contiene datos sobre los precios de venta sobre 2014 y 2015 en el condado de King, Estados Unidos. 

El objetivo de la práctica es construir un modelo de predicción para el precio de la vivienda (variable price), en función de tantas variables de entrada como estimemos conveniente.

## Limpieza de variables

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(readr)
library(dplyr)
library(Hmisc)
library(ggplot2)
library(VIM)
library(summarytools)
library(glmnet)

source('transformations.R')

set.seed(12345)
```

### Train y Test

Separación de los datos en training set (70% de los datos) y testing set (30% restante de los datos).
Primero leemos el archivo y se crea una partición para separar los datos en train y test.

```{r train test}
kc_house_data <- read_csv("data/kc_house_data.csv")
inTraining <- createDataPartition(pull(kc_house_data), p = .7, list = FALSE,times = 1)

house_training <- slice(kc_house_data, inTraining)
house_testing <- slice(kc_house_data, -inTraining)
```

### Exploratory Data Analysis (EDA)

El EDA se realiza sobre los datos de entrenamiento. Se identifican las posibles operaciones que debemos realizar sobre los datos.

De una forma general, se empieza a analizar los datos (tipo de variable, frecuencia, distribución, datos faltantes, etc.)
```{r}
summary(house_training)
```

Al hacer la limpieza con los datos de entrenamiento, encontramos duplicados en la variable `ID`. Se han ordenado en base a la variable `date` de manera descendente para quedarnos con las fechas más actuales y eliminar las casas duplicadas que han sufrido algún cambio como puede ser una nueva reforma o un nuevo valor del precio de la vivienda.

```{r}
# Discard duplicated ids.
duplicated_ids <- house_training[which(duplicated(house_training$id)),]
house_training_order <- house_training[order(house_training$date, decreasing = TRUE),]
house_training <- house_training_order[!duplicated(house_training_order$id), ]
```

La variable bathrooms contiene valores a 0 y se reemplazará por NA.

```{r}
# Set NAs.
house_training$bathrooms <- house_training$bathrooms %>% dplyr::na_if(0)
```

```{r}
# Binary variables
house_training <- house_training %>% mutate(has_basement = if_else(sqft_basement == 0, 0,1))
house_training <- house_training %>% mutate(renovated = if_else(yr_renovated == 0, 0,1))
```

La variable bedrooms contiene un único valor extremadamente átipico de 33 que parece ser un error.
Primero se le imputa como NA y después se realiza la función de K-NN usando los 5 vecinos más cercanos para asignarles un valor a los NAs.

```{r}
# Impute values
house_training$bedrooms <- house_training$bedrooms %>% dplyr::na_if(33)
house_training <- kNN(house_training, variable = c("bedrooms"), dist_var = c("sqft_living", "floors", "has_basement"), k = 5, imp_var = FALSE)
```

Las siguientes variables muestran grandes colas que indican que seria requerible transformarlas usando el logaritmo:

```{r}
# logarithmic plots
house_training
```


```{r}
# logarithmic transformations
house_training <- mutate(house_training, price = log(price))
house_training <- mutate(house_training, sqft_living = log(sqft_living))
house_training <- mutate(house_training, sqft_lot = log(sqft_lot))
house_training <- mutate(house_training, sqft_lot15 = log(sqft_lot15))
```


## Regresión múltiple

```{r}
glm.fit = glm(price ~ ., data=house_training)

summary(glm.fit)
coef(glm.fit)
cv.error.10=rep(0,10)
y_train <- house_training$price
y_hat <- predict(glm.fit, newdata = house_testing, type="response")
y_real <- house_testing$price
error_test=sum(abs(y_hat-y_real))/length(y_real)
```

## 4. Selección de variables con LASSO

Utilizaremos validación cruzada para elegir el parámetro lambda que mejor se ajuste a nuestros datos.
Elegiremos aquel que se diferencie en una unidad de error estandar con respecto al valor de lambda óptimo (el que maximiza el AUC)

```{r echo=TRUE}
house_training <- na.omit(house_training)
x_train <- model.matrix(price~.,house_training)[,-1]
y_train <- house_training$price

cv.out <- cv.glmnet(x_train, y_train, alpha=1, nfolds=10, type.measure="mse")
plot(cv.out)
```

Se observa que el error cuadrático medio para lambda0 y lambda1 es muy pequeño, signo de que jlo que es un buen síntoma.

- Valor de lamba con el que entrenaremos: 

```{r echo=TRUE}
cv.out$lambda.1se
```

- Coeficientes del Lasso:

```{r echo=TRUE}
tmp_coeffs <- coef(cv.out, s = "lambda.1se")

tmp_coeffs
```


- **5. Predicción en Test**

```{r echo=TRUE}
house_testing <- transform(house_testing)
house_testing <- na.omit(house_testing)
x_test <- data.matrix(house_testing %>% select(-price))

y_predicted_test=predict(cv.out,newx = x_test, type = "response")
y_real_test = house_testing$price

mean((y_real_test - y_predicted_test)^2)
```